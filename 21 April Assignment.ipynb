{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0190c0-6f32-42b8-9d80-9feef43152d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance\n",
    "metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdffa3a5-e6a3-402b-ac4a-ff93fd4907cd",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e99e530-2bda-4610-bfc8-3fe3d34e2e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "The main difference between the Euclidean distance metric and the Manhattan distance metric in KNN is that the Euclidean distance\n",
    "is based on squared error distance, whereas Manhattan distance is based on absolute value distance. \n",
    "Euclidean distance is harder to calculate by hand because you have to square the differences, add them up, and take the square root.\n",
    "Manhattan distance is easier to calculate by hand because you just subtract the values of each dimension, take the absolute value,\n",
    "and add them up.\n",
    "\n",
    "The choice of distance metric can affect the performance of a KNN classifier or regressor.\n",
    "In general, Euclidean distance works well when the data is dense or continuous. \n",
    "Manhattan distance works well when the data is sparse or categorica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a352b2b1-4674-4682-9122-095b9819a94e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd10524-ac31-4793-b180-256d0b4ba34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be\n",
    "used to determine the optimal k value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834cea47-418a-433a-9501-d14fc58152b7",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bbce44-f4b7-4094-b773-5dfddc9095e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "The optimal value of k for a KNN classifier or regressor is usually determined by trial and error. \n",
    "There are no pre-defined statistical methods to find the most favorable value of k. \n",
    "However, there are some thumb rules that can be used to choose the optimal k for your problem and data.\n",
    "One such rule is k = n^ (1/2), where n is the number of data points in the training data.\n",
    "\n",
    "Another rule of thumb is to choose an odd number if the number of classes is 2. \n",
    "Choosing a very small value of k leads to unstable decision boundaries, while a large value makes it computationally expensive.\n",
    "\n",
    "There are also some techniques that can be used to determine the optimal k value. \n",
    "One popular way of choosing the empirically optimal k in binary (two-class) classification problems is via bootstrap method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c295e33-7b9e-4da5-8c63-e309d2d78f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910bb13b-57d8-4a51-b2c4-5f44f3179853",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? In\n",
    "what situations might you choose one distance metric over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c33e713-ca7b-44bb-998d-152791fef94f",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb1eae-8cab-4f95-8972-003575baae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "The choice of distance metric can significantly affect the performance of a KNN classifier or regressor. \n",
    "The performance of KNN classifier depends significantly on the distance used, and the results showed large gaps\n",
    "between the performances of different distances. \n",
    "The best choice of k depends upon the data; generally, larger values of k reduces effect of the noise on the classification,\n",
    "but make boundaries between classes less distinct. It is recommended to have an odd number for k to avoid ties in classification.\n",
    "\n",
    "The most widely used distance metric in KNN classifications is Euclidean distance.\n",
    "However, only few studies examined the effect of different distance metrics on the performance of KNN, \n",
    "these used a small number of distances, a small number of datasets, or both.\n",
    "Such shortage in experiments does not prove which distance is the best to be used.\n",
    "\n",
    "In general, Manhattan distance is preferred over Euclidean distance when we have a case of high dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d057542-d51f-474f-8be6-8d6551ddc8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc9dd9-7225-4641-880b-9e2f73f31a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect\n",
    "the performance of the model? How might you go about tuning these hyperparameters to improve\n",
    "model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c204b5-d9e9-4bee-a378-f9aff9e12a8d",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776a66b-d7da-49c2-b3ae-40ceb5a0322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN classifiers and regressors have several hyperparameters that can be tuned to improve the performance of the model. \n",
    "Some common hyperparameters are:\n",
    "\n",
    "1.n_neighbors: The number of neighbors to consider when making predictions. Increasing this value can lead to a smoother decision boundary, \n",
    "               but too many neighbors can lead to overfitting.\n",
    "    \n",
    "2.weights: The weight function used in prediction. The default is 'uniform', which gives equal weight to all neighbors.\n",
    "           Another option is 'distance', which gives more weight to closer neighbors.\n",
    "    \n",
    "3.algorithm: The algorithm used to compute nearest neighbors. The default is 'auto', which chooses the most appropriate algorithm based on\n",
    "             the values of n_samples and n_features. Other options include 'ball_tree', 'kd_tree', and 'brute'.\n",
    "    \n",
    "4.leaf_size: The size of the leaf node in the KD tree or Ball tree. This can affect the speed of the algorithm.\n",
    "\n",
    "5.p: The power parameter for the Minkowski metric. When p=1, this is equivalent to using Manhattan distance. \n",
    "     When p=2, this is equivalent to using Euclidean distance.\n",
    "\n",
    "To tune these hyperparameters, you can use techniques such as grid search or randomized search. \n",
    "Grid search involves specifying a range of values for each hyperparameter and testing all possible combinations of these values. \n",
    "Randomized search involves randomly sampling from these ranges and testing a smaller subset of possible combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437477e7-f045-4ee1-82ef-11c068174d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da5336-ca5d-4faa-9983-11c47ea492f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. How does the size of the training set affect the performance of a KNN classifier or regressor? What\n",
    "techniques can be used to optimize the size of the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c22d99-3128-4805-bbd3-f1a0fce890fa",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bed8ca-bdbb-4148-91dc-13c96c798c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "The size of the training set can affect the performance of a KNN classifier or regressor.\n",
    "When the size of the training set is too small, the model may not be able to capture the underlying patterns in the data \n",
    "and may result in overfitting.\n",
    "On the other hand, when the size of the training set is too large, it may result in underfitting. \n",
    "The optimal size of the training set depends on the complexity of the problem and the amount of noise in the data.\n",
    "\n",
    "To optimize the size of the training set, one approach is to use cross-validation. \n",
    "Cross-validation is a technique that involves dividing the data into multiple subsets and using each subset as both a training set and\n",
    "a validation set.\n",
    "Another approach is to use a learning curve to determine the optimal size of the training set. \n",
    "A learning curve plots the modelâ€™s performance as a function of the size of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3769b255-e181-447c-9acb-393614da06e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7be2358-357a-41f5-b9a4-44ca31c8b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. What are some potential drawbacks of using KNN as a classifier or regressor? How might you\n",
    "overcome these drawbacks to improve the performance of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1411f-c9e8-4726-8c12-7b3f0dfcee09",
   "metadata": {},
   "source": [
    "ANS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6df488-5876-499b-a45a-e5047698399a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f49f71e-c43c-47b0-955a-15ac0ba4cfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b5915c-8cae-46c6-890e-7b3baab80e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2492a6d3-4781-47ee-9701-8c302861fb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c11dc-7772-49e1-9149-b0b1a8a1d8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dbb617-3d8b-455f-a8d7-9eccb9aa8e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0237f5ec-6678-4362-9067-18c3ad7e0037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a524562a-18c3-4013-b158-2679d71297de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d81866d-3377-4329-be08-5f43b4331295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c5e52-f553-4148-b80d-1c4b7731164c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ee890-ad49-4311-b290-eb3379aaa132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
